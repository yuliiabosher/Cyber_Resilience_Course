{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuliiabosher/Cyber_Resilience_Course/blob/main/Reading_from_and_saving_to_S3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connecting to AWS Simple Storage System (S3)\n",
        "---\n",
        "To connect to, read files from and write files to S3 you will need the following:\n",
        "\n",
        "\n",
        "\n",
        "*   Get an access key (which you should keep hidden)  \n",
        "*   install the python library `boto3`   \n",
        "*   write a function get an S3 connection\n",
        "*   read or write a file as you need to\n",
        "\n"
      ],
      "metadata": {
        "id": "OLyJadlYUQ30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use this code cell to install boto3 for use in this worksheet\n",
        "---\n",
        "Use this code to do this:\n",
        "`!pip install boto3`\n",
        "\n",
        "***Note 1***:  you will need to do this each time you come back to the worksheet.  If someone else copies your worksheet, they will need to install it.\n",
        "\n",
        "***Note 2***: once you have installed it in a session, you won't need to install it again, so put the code in a cell that you only run once."
      ],
      "metadata": {
        "id": "Msbx3QBoWEF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install boto3"
      ],
      "metadata": {
        "id": "jHUliNAyWlej",
        "outputId": "ab4b2300-8046-4c23-da9a-419e511aa505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boto3\n",
            "  Downloading boto3-1.34.35-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.35.0,>=1.34.35 (from boto3)\n",
            "  Downloading botocore-1.34.35-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.35->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.35->boto3) (2.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.35->boto3) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.34.35 botocore-1.34.35 jmespath-1.0.1 s3transfer-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save your access key, and secret key in an environment variable\n",
        "---\n",
        "\n",
        "During testing you will save the keys in environment variables here.  When you create a function in lambda you will use the environment variables there.\n",
        "\n",
        "1.  In the AWS console - go to the IAM service.  Follow instructions here to create your access keys: https://docs.google.com/document/d/1_FhKLVLSaBdck1e-Pm4mlUQkIj9BGwPfuquMPHpXdls/edit?usp=sharing   \n",
        "2.  Once you have downloaded the keys in a CSV so that you have a permanent record to copy and paste from (kept on your own device, or in your own cloud storage if you can't store on the device), you will be able to use them to connect to S3.\n",
        "\n",
        "3.  Create a bucket (a folder) to store your files.  Follow the instructions here: https://docs.aws.amazon.com/AmazonS3/latest/userguide/creating-bucket.html  (there is quite a bit of information about changing setting, leave everything as the default for this exercise)  \n",
        "\n",
        "3.  Use the code cell below to allow you to input the public key (AWS_ACCESS_KEY), the private key (AWS_SECRET_ACCESS_KEY), and the bucket name,  and save all three in environment variables only available in this worksheet while you are using it.\n",
        "\n",
        "***Note 2***:  you will need to do this each time you come back to the worksheet.  If someone else copies your worksheet, they should not be able to upload to your S3 as they won't know the keys and they won't know the bucket URL (as you will also save that in an environment variable)"
      ],
      "metadata": {
        "id": "EZhg5WXdW8na"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0V-74wDUUCiC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def set_environment_variable_values():\n",
        "  ACCESS_KEY = input(\"Please enter the AWS access key: \")\n",
        "  SECRET_ACCESS_KEY = input(\"Please enter the AWS secret access key: \")\n",
        "  BUCKET_NAME = input(\"Please enter the name of the bucket in S3: \")\n",
        "  os.environ['ACCESS_KEY'] = ACCESS_KEY\n",
        "  os.environ['SECRET_ACCESS_KEY'] = SECRET_ACCESS_KEY\n",
        "  os.environ['BUCKET_NAME'] = BUCKET_NAME\n",
        "  clear_output()\n",
        "  return None\n",
        "\n",
        "set_environment_variable_values()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### You can use the cell below to check that your environment variables have been saved, but clear the output before you upload this to github\n",
        "---\n"
      ],
      "metadata": {
        "id": "lbncziG5szFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.environ.get('ACCESS_KEY'), os.environ.get('SECRET_ACCESS_KEY'), os.environ.get('BUCKET_NAME'))"
      ],
      "metadata": {
        "id": "BzANqlxyTNhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a connection to the S3 bucket\n",
        "---\n",
        "\n",
        "In order to work with files in the bucket you will need a 'client'.  This will be the worker that will do the fetching and storing.  The code below will set up this client and the output will show that a client has been created."
      ],
      "metadata": {
        "id": "EyLPbMMlTe63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "\n",
        "def get_S3_client():\n",
        "\tresource = boto3.client(\n",
        "     \"s3\",\n",
        "\t\taws_access_key_id = os.environ.get('ACCESS_KEY'),\n",
        "\t\taws_secret_access_key = os.environ.get('SECRET_ACCESS_KEY')\n",
        "\t)\n",
        "\treturn resource\n",
        "\n",
        "s3_client = get_S3_client()\n",
        "print(s3_client)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm0Hz9JEUwxE",
        "outputId": "f0457d6f-73d3-47db-cf78-a485d8b9ed9f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<botocore.client.S3 object at 0x7a266bb2dd80>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Opening a file from S3\n",
        "---\n",
        "\n",
        "You can upload this file to your bucket, through the AWS console.  \n",
        "\n",
        "*  Download the file (population.csv) from here:  https://drive.google.com/file/d/1Mj2f56YrgWL6eYUF9zOf0Pph8NhJAIe0/view?usp=sharing\n",
        "\n",
        "*  Open the AWS dashboard and select S3 as the service.  \n",
        "\n",
        "*  Find your bucket and click on its link to open it.  \n",
        "\n",
        "*  Click on **upload**, select the file and upload\n",
        "\n",
        "Now that the file is in the bucket, use the code below to open it."
      ],
      "metadata": {
        "id": "qfwQ9T_ZV4oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "def get_file(filename):\n",
        "  # get the file from the bucket\n",
        "  file_object = s3_client.get_object(Bucket=os.environ.get('BUCKET_NAME'), Key=filename)\n",
        "\n",
        "  # convert the file object to a text-based csv file then read the file contents into a table using the pandas read_csv function\n",
        "  data_file = io.BytesIO(file_object['Body'].read())\n",
        "  data = pd.read_csv(data_file)\n",
        "  return data\n",
        "\n",
        "data = get_file('populations.csv')\n",
        "print(data)"
      ],
      "metadata": {
        "id": "2o-HkfsuX26E",
        "outputId": "81b95155-1f44-4e00-c363-0e8d9a73ea33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Town   population\n",
            "0    Glasgow       635130\n",
            "1     Medway       280890\n",
            "2  Edinburgh       558670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload a new file into your bucket\n",
        "\n",
        "---\n",
        "\n",
        "For this exercise you are going to make a new data file (using pandas.to_csv to make the csv file, then BytesIO to convert it into a bytes object that can be stored on S3)"
      ],
      "metadata": {
        "id": "5L3F6bV9iVJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_a_copy(filedata, filename):\n",
        "  # first copy the data into a new file (print it so that you know it has been done)\n",
        "  new_data = filedata.copy()\n",
        "  print(new_data)\n",
        "\n",
        "  # make a text file object to store the data in, then convert the data csv format and place inside the file object\n",
        "  file_object =  io.StringIO()\n",
        "  new_data.to_csv(file_object, index=False)\n",
        "\n",
        "  # upload the file to the bucket with the filename and the file contents\n",
        "  response = s3_client.put_object(Bucket=os.environ.get('BUCKET_NAME'), Body=file_object.getvalue(), Key=filename)\n",
        "\n",
        "response = save_a_copy(data, 'populations_copy.csv')\n",
        "print(response)"
      ],
      "metadata": {
        "id": "qWBJVTI-lJ8t",
        "outputId": "f05664ba-db89-41b1-e950-4da8b2cdd5b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Town   population\n",
            "0    Glasgow       635130\n",
            "1     Medway       280890\n",
            "2  Edinburgh       558670\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a serverless function that will read a file and return the data\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "jh3eThd6SMTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learn how to read and write files to an S3 bucket, keeping the access keys secret. Write and test a serverless function that will read a csv file from s3 and return the contents."
      ],
      "metadata": {
        "id": "hMqA3Q6FR1Dh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qwGPFmzpSfL3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}